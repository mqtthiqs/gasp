\documentclass{article}

\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage{mathpartir}
\usepackage{color}
\usepackage[backref=page,colorlinks=true]{hyperref}
\usepackage{amsmath, amstext, amsthm, amsfonts}
\usepackage{stmaryrd}
\usepackage{geometry}
\usepackage{natbib}
\usepackage{fancyhdr}
\usepackage[all,cmtip]{xy}
\usepackage[protrusion=true,expansion=true]{microtype}

\definecolor{bwgreen}{rgb}{0.183,1,0.5}
\definecolor{bwmagenta}{rgb}{1,0.169,0.909}
\definecolor{bwblue}{rgb}{0.317,0.161,1}
\hypersetup{
  linkcolor=blue,
  citecolor=blue
}

\newcommand{\sort}{\textsf{s}}
\newcommand{\gor}{\ |\ }
\newcommand{\gdecl}[2]{{#1}\ &::=\ {#2}}
\newcommand{\subst}[2]{\{#1/#2\}}
\newcommand{\nat}{\mathbb N}

% Commandes à désactiver avant la soumission.
% Remarques sur la structure.
\newcommand{\remplan}[1]{\noindent\textcolor{bwblue}{$\triangleright$ \textbf{#1}}}
% Remarques sur le contenu.
\newcommand{\remtext}[1]{\textcolor{bwgreen}{$\triangleright$ \textsl{#1}}}

\renewcommand{\remplan}[1]{}
\renewcommand{\remtext}[1]{}

\title{Towards typed repositories of proofs}

\author{Matthias Puech \and Yann Régis-Gianas}
\date{}

\begin{document}

\maketitle

\paragraph{Motivations}

\remplan{Motivations générales}

Practical efforts in the formalization of mathematical results have
naturally led to the questions of how to manage large repositories of
proofs, i.e. what is the \emph{daily workflow} of users of a proof
assistant. How does one elaborate a formal proof? What kind of \emph{a
  posteriori} modification is he prone to doing? What do these
modifications imply on the validity of the whole edifice or, the other
way around, how does one rely on existing work to build up new results?
Many of these questions remain largely unanswered, but the tendency
seems to be to adapt existing methods coming from software
development, as illustrated for example by the introduction of
modules, file-based scripts and separate compilation in proof
assistants like \textsf{Coq}~\cite{CoqDocWeb} or
\textsf{Matita}~\cite{AspertiCTZ07}, the use of
dependency management tools (\textsf{Make}) or version control system
(\textsf{GIT}, \textsf{Subversion}) to build and manage versions of a
project. Both for the development of proofs or programs, these tools
attempt to cope with the fact that most of a mathematician or
programmer's time is actually spent \emph{editing}, not
\emph{writing}.

We believe that these tools are not adapted for the new, demanding
requirements of proof developments. Indeed, whereas compilation of a
program is usually fast enough for the programmer to rely on the usual
interaction loop ((edit; compile)*; commit)*, the operation of proof
checking is usually too expensive computationally to mimic this
workflow. But even besides the time factor, this ``traditional'' way
of formalizing mathematics hinders the process of mathematical
discovery process: once a concept contained in a file is compiled, it
is considered frozen and any changes to it require the recompilation
of the whole file; the linearity of the development also gives no room
for alternate, inequivalent definitions. This fact has nonetheless
been shown to be of crucial to the mathematical discovery
process~(\cite{lakatos1964proofs}), and we believe that they should be
taken into account in the realization of mathematical assistants.

In fact, although dedicated tools exist to formalize the description
of languages and their metatheory (e.g. \textsf{Twelf},
{\cite{pfenning1999system}}), and substantial formalizations have been
undertaken\cite{lee07}, we still use legacy tools based on text
representation to manage our developments. The general goal exposed
here is to replace this tool chain and make it language-aware, both on
a syntactic side through the use of abstract syntax trees (AST) instead of
concrete syntax and on a semantic side by using typing to ensure 
repository consistency.

% \remplan{Sujet du papier : on focalise sur un problème bien précis}

%% \remtext{Fri Jun 18, 2010 10:00 AM.
%%   Un peu de liant. Pour arriver à notre but, il y a une
%%   question importante à résoudre: si on te donne une méta-théorie
%%   formalisée, es-tu capable de décrire l'historique d'un développement
%%   dans cette théorie? Cela induit deux questions : dans quel langage
%%   et est-ce que ce langage est utilisable (parce qu'a priori, ce n'est
%%   pas gagné car le développeur travaille en mode ``instantané'' et ne
%%   veut pas se trimballer ses casseroles tout le temps\ldots).}

We propose to discuss a small part of these questions, namely the
enhancement and adaptation of version control paradigms to the
management of mathematical repositories, to witness with more
precision the \emph{impact of changes}. Following the Type Theory
approach, our work is based on an algebra of expressive types that are
meant to assign precise specifications to object-level term
constructors and, in the meantime, capture fine-grained
dependencies between these objects.

%% In proof assistants based on
%% the propositions-as-types paradigm, Type Theory offers a powerful tool
%% to witness the effect of changes finely: types, and we base our work
%% on these.

We will describe some of the possible directions to develop a tool to
analyze the impact of changes through types. It involves at its core a
typed description language for repositories, and is strongly related
to incremental type-checking: only differences between versions are
type-checked and not the entire development. In the first iteration of
this project, we focus on a static, or data-driven model for
repositories inspired by the repository model of \textsf{GIT}.

\paragraph{A core language to describe typed repositories}

The kernel of our system is a type-checker algorithm for a typed
meta-language. In this language, we will declare both the syntax of
the object (proof-)language and its typing rules, and define pieces of
syntax (our proofs) and their derivations. Describing transformations
among syntax objects is done by sharing common subterms or
subderivations.

Representing syntax and logics is nicely done in a \emph{logical
  framework} like LF: both the syntactic elements and the typing
derivations can sit in the same tree structure, and both can be
rechecked at the same time, thanks to dependent types. For the purpose
of incremental type checking though, our needs are a little bit
different: first, we need to record, that is to name all intermediate
values of our developments, so as to be able to address and reuse them
multiple times. Secondly, we need to make sure that those intermediate
values (sub-terms) are not recorded twice, so as to not type-check
them twice: we are looking to represent syntactic and typing objects
as a DAG rather than a tree. Moreover, we enforce by typing a property
of \emph{maximal sharing}: every different subterm can be constructed
exactly once. Our system will have these properties w.r.t. LF:
\begin{itemize}
\item In this first iteration of the project, we do not need
  computations to take place within our DAGs. Our syntax will then be
  restricted to product types and applications;
\item Every term should be a flat application of variables, so that we
  don't introduce compound terms without naming them and recording
  their types;
\item Finally we need a way to record intermediate definitions: we
  introduce a new kind of binder, the equality binder. We maintain the
  invariant that not two same definition can sit in the context while
  typing, thus guaranteeing \emph{maximal sharing} among terms and
  derivations.
\end{itemize}

We describe the state of a repository at a given moment by a type $t$
in the following syntax. Well-typed types in the repository
meta-language guarantee that it contains only well-typed proofs in the
object language.
\begin{align*}
 \gdecl{a}{x \gor a\ x } \\
 \gdecl{t}{a \gor \sort \gor (x:t)\cdot t \gor (x=a:t)\cdot t}
\end{align*}

From an implementation point of view, following \textsf{GIT}, we store
these terms in a database of objects indexed by \emph{keys}, which are
hash values of their contents, so that retreiving the type of a whole
term boils down to compute its hash, and look for it in the database.

Note that in this system, computation has no existence: we only
provide ways to verify that syntax and typing rules of an object
language are correct. Therefore, patches -- functions from
repositories to repositories -- have no existence \emph{per se}. A
necessary enhancement of our theory would be to consider computation
as a way to apply patches as if they were constructive
metatheorems. We conjecture that it would be done by re-extending the
system towards LF (adding abstraction and reduction).

\paragraph{Related works}
\label{rw}

The \textsf{Twelf} project~\cite{pfenning1999system} is an
implementation of the Logical Framework (LF,
\cite{harper1993framework}). It was used in \cite{anderson1993program}
to devise transformations of proofs in order to extract efficient
programs. Our kernel language reformulates LF by a syntactic
explicitation of dependencies.

The problems of managing a formal mathematical library have been dealt
with in various proof assistant and mathematical repositories. The
HELM project~\cite{asperti2006content} was an attempt to create a
large library of mathematics, importing \textsf{Coq}'s developments
into a searchable and browsable database.  Most ideas from this
project were imported into the \textsf{Matita} proof
assistants~\cite{AspertiCTZ07}, especially a mechanism of
\emph{invalidation and regeneration} to ensure the global consistency
of its library w.r.t changes, with granularity the whole definitions
or proofs and their dependencies. The MBase
project~\cite{kohlhase2001mbase} attempts at creating a web-based,
distributed mathematical knowledge database putting forward the idea
of \emph{development
  graph}~\cite{hutter2000management,autexier2000towards} to manage
changes in the database, allowing semantic-based retrieval and
object-level dependency management. 
% Y: Un mot pour se comparer a ces travaux?

This idea, generalized over structured, semi-formal documents gave
birth to \texttt{\it locutor}~\cite{muller2008fine}, a fine-grained
extension of the \textsc{svn} version control system for XML
documents, embedding ontology-driven, user-defined semantic knowledge
which allows to go across the filesystem border. It embeds a
\emph{diff} algorithm, operating on the source text modulo some
equality theory to quotient the syntax. On the same line of work, we
should mention the \emph{Coccinelle} tool
(\cite{padioleau2008documenting}). It is an evolution over textual
patches, specialized on the C language, allowing more flexibility in
the matching process, and was developed to deal with the problem of
\emph{collateral evolutions} in the Linux kernel. It embeds a
declarative language for matching and transforming C source code,
operating on text modulo defined isomorphisms.
% Y: meme chose, comment on se compare sur ce point? 

Our approach to the ``impact of changes'' problem seems novel on
several aspects: first, it applies uniformly on proofs and programming
languages by virtue of the Curry-Howard isomorphism, and because we
operate at the AST level. Secondly, by taking \emph{types} as 
witnesses for the evolution of a development, we refine the usual,
dependency-based approach for a finer granularity.

% \section{Further work}
% \label{fw}

% \remtext{Extension vers une version constructiviste?}

% \remtext{Parler du bootstraping?}

% \section{Conclusion}

%% In the light of the propositions-as-types paradigms where
%% proof-checking boils down to type-checking, we abstract from whether
%% we are talking about proofs or programs, so that our development could
%% eventually also be used in traditional software development.

%% \section{Methodologies}

%% We propose here to devise a system for \emph{semantic repositories}. It
%% % TODO changer le nom?
%% substitutes the idea of textual transformation by:
%% \begin{itemize}
%% \item First preferring an abstract syntax tree representation instead
%%   of plain text;
%% \item Secondly embedding semantic, or typing data into the
%%   transformations, in order to be able to reason on them.
%% \item Finally, perform type-checking in an incremental way, that is
%%   type only the syntactic difference and reuse derivation for the
%%   already known subprograms.
%% \end{itemize}

%% We want to design a \emph{language of repositories}, able to represent
%% % TODO changer le nom?
%% these transformations and their semantic properties, thus capturing
%% local syntactic changes in programs (the abstract syntax tree), as
%% well as their global effect on the whole project (the typing
%% derivations). We can see this goal as a refinement of the former idea
%% of ``dependency''.

\bibliographystyle{plainnat}

\bibliography{english}

\end{document}
